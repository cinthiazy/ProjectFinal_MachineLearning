---
title: "Machine Learning Project"
author: "Author: Cinthia Zarabia"
output: html_document
---

 In this project, we will use a database containing information from six young health participants who performed a set of 10 repetitions of Unilateral Dumbbell Biceps Curl in five different ways: exactly according to the specification (Class A), throwing the Elbows to the front (Class B), raising the dumbbell only in the middle (Class C), lowering the dumbbell only midway (Class D) and throwing the hips in front (Class E). And the goal of the project is to predict how they did the exercise. This is the **class** variable in the training set.More information is available from the website here: <http://groupware.les.inf.puc-rio.br/har> (see the section on the Weight Lifting Exercise Dataset).


### **Load Data Test and Training**
```{r echo=TRUE}
setwd("E:/CURSOS/CURSO MACHING LEARNING-Coursera/Project/ModeloenR");
testing<-read.csv("pml-testing.csv");
training<-read.csv("pml-training.csv");
```

### **Split the data in train and test**

```{r eval=FALSE}
install.packages("caret");
install.packages("dplyr");
library(caret);
library(dplyr):
```

```{r echo=FALSE}
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(dplyr)))
```

```{r echo=TRUE}
set.seed(125) 
adData = training       
testIndex = createDataPartition(adData$classe, p = 0.30,list=FALSE)
train = adData[-testIndex,]
test = adData[testIndex,]
```

* The data train has the 70% and test has 30 % all data training and both have the same characteristics. 

```{r echo=TRUE}
dim(train)
dim(test)
round(100*prop.table(table(train$classe)),2)
round(100*prop.table(table(test$classe)),2)
```

### **Summary in data**
```{r}
dim(train)
summary(train[,5:20])
```

When make the summary in data,  be observe it  the data has many values Missing and NA, for this reason be will analysis the attributes.

### **Explorary the data**

* Will be identificate  the attributes with higher percentage the NA, and then remove those variables from the data.

```{r echo=TRUE}
NAS<-colnames(train)[colSums(is.na(train)) >(dim(train)[1])*0.50]
NAS
train<-train[,-which(names(train) %in% NAS)];
```

Now the data will has 67 columns less in the dataset :

```{r echo=TRUE}
dim(train);
```

* Will be identificate  the attributes with values Nulls with percentage higher the  50 %, and then remove those variables from the data.

```{r echo=TRUE}
NULOS<-colnames(train)[colSums(train == "") >(dim(train)[1])*0.50];
NULOS;
train<-train[,-which(names(train) %in% NULOS)];
```

Now the data will has 33 columns less in the dataset :

```{r echo=TRUE}
dim(train);
```

* We will be eliminated 4 variables for the following reasons: 

Removing columns with little variability between Categories.

```{r echo=TRUE}
nzv_cols <- nearZeroVar(train,names = TRUE)
nzv_cols
train<-if(length(nzv_cols) > 0) train[,-which(names(train) %in% nzv_cols)]
dim(train)
```

ID names, date in which they performed the exercise and row number in that order respectively.

```{r echo=TRUE}

nombres<-c("user_name","cvtd_timestamp","X")
train<-train[,-which(names(train) %in% nombres)];
dim(train); 
```


```{r echo=TRUE}
dim(train);
```

Now the data will has 56 columns in the dataset y the renames that train:

```{r echo=TRUE}
train<-train;
```


### **Selection the variables**

* Will be use the Random Forest for the analysis the variable selection .

```{r eval=FALSE}
install.packages("randomForest");
library(randomForest);
library(dplyr);
```

```{r echo=FALSE}
suppressWarnings(suppressMessages(library(randomForest)))
suppressWarnings(suppressMessages(library(dplyr)))
```

```{r echo=TRUE}
set.seed(33833)
modFit_rf = randomForest(classe ~., data=train,importance=TRUE);
ImportGini = data.frame(importance(modFit_rf)[,7]);
colnames(ImportGini) = "MeanDecreaseGini";
variables = row.names(ImportGini)
PesosGini = data.frame(cbind(variables,ImportGini), row.names = NULL)
PesosGini = arrange(PesosGini, desc(MeanDecreaseGini))
PesosGini= filter(PesosGini,MeanDecreaseGini<0.08*max(PesosGini["MeanDecreaseGini"]))[1]
PesosGini=as.vector(PesosGini$variables)
PesosGini
train = train[ , -which(names(train) %in% PesosGini)];
dim(train)
```


```{r echo=FALSE}
rm(modFit_rf,ImportGini,variables)
rm(PesosGini)
```

* Then be get the 34 variables more importants considering  this criterious, and will be analyse the correlation in this variables:


```{r eval=FALSE}
library(caret);
library(lattice);
library(ggplot2);
```

```{r echo=FALSE}
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(lattice)))
suppressWarnings(suppressMessages(library(ggplot2)))
```


```{r echo=TRUE}
train_numerica = train[ , -which(names(train) %in% c('classe'))];
cor_var= findCorrelation(x= abs(cor(train_numerica,method="pearson")), cutoff=0.6, names=TRUE);
cor_var;
```

Then will be removed las 11 variables with correlation high than 0.6 . So now the data set has 18 variables.


### **Model Development**

* Will be built the data set for the development the model with variables seleccionados previously, then tested in the test data and the Data for predict .

** Training Data  

```{r echo=TRUE}
dim(train);
```

**  Test Data 
```{r echo=TRUE}
variables<-names(train)
test<-test[,which(names(test) %in% variables)];
dim(test);
```

** Data for predict  
```{r echo=TRUE}
variables<-names(train)
testing<-testing[,which(names(testing) %in% variables)];
dim(testing);
```


* The algorithm selected for the development of the model was Random Forest, since it was the technique that gave us better performance.

```{r eval=FALSE}
install.packages("randomForest")
library(randomForest);
library(caret);
```

```{r echo=FALSE}
suppressWarnings(suppressMessages(library(randomForest)))
```

```{r echo=TRUE}
modelRF= randomForest(classe ~., data=train, importance=TRUE);   
modelRF
```

* Will be evaluated the performance the model.

** Model Sensitivity
```{r echo=TRUE}
classe=row.names(modelRF$confusion)
sensibility = rep(0,5)
for(i in 1:5)
{ sensibility[i] = round(100*(modelRF$confusion[i,i]/sum(modelRF$confusion[i,1:5])),2)}
sensibility

sensib.Model=cbind(classe,sensibility)
sensib.Model
```

** Positive Predictive Values(VPP) 
```{r echo=TRUE}
Predict.Clas = apply(modelRF$confusion[,1:5],2,sum)
Predict.Clas
VPP = rep(0,5)
for(i in 1:5)
{ VPP[i] = round(100*( modelRF$confusion[i,i]/Predict.Clas[i]), 2) }
VPP
```

** Correct Classification Rate
```{r echo=TRUE}
Accuaracy_Train = 100*sum(diag(modelRF$confusion))/sum(modelRF$confusion[,1:5])
Accuaracy_Train
```

* Will be evaluated the performance the model in Test Data. 


** Positive Predictive Values(VPP) 
```{r echo=TRUE}
Predic.Test = predict(modelRF, test, type="response");
MatrixConf=table(test$classe,Predic.Test)
MatrixConf

sensib.Test=round(100*( diag(MatrixConf)/table(test$classe)),2)
sensib.Test
```

** Correct Classification Rate (Accuaracy)
```{r echo=TRUE}
Accuaracy_Test = 100*sum(diag(MatrixConf))/sum(MatrixConf)
Accuaracy_Test
```

** The Accuary the training data is 99.75% y test data is 99.76%,also the sensibilidad and Positive Predictive Values are high, so can say the model has good performance.

* Now you will scoring the Data for predict(testing data) with the selected model.
```{r echo=TRUE}
Predic.Val = predict(modelRF,testing, type="response");
Predic.Val
```



